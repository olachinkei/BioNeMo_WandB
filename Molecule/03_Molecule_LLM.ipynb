{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce8b6a4",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "Please check the [wandbのreport](https://api.wandb.ai/links/wandb-healthcare/jm7scchv) for details on setting up the environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7dc4b-464c-477c-aa41-723c5b24e7a8",
   "metadata": {},
   "source": [
    "## Weights and Biases setup\n",
    "The progress and charts of model training can be visualized through Weights and Biases (wandb). Please refer to the above report for instructions on setting up wandb. Below, you will set up the entity and project, which are the storage locations for wandb. Please enter any values you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64217436-2c05-4c1a-be92-2e7a93a780fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"WANDB_ENTITY\"]=\"wandb-healthcare\"\n",
    "os.environ[\"WANDB_PROJECT\"]=\"BioNeMo_Molecule_LLM\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8536eb8",
   "metadata": {},
   "source": [
    "## Confirmation of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b551d-2e18-4670-90ab-a277dc036bf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Confirmation of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf18a8-cd3e-4407-a21c-b721f89b5337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ab40b-b288-44f9-8a09-c1ee1679a0cc",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be07928-e27a-4445-a662-90ca671f1285",
   "metadata": {},
   "source": [
    "We will use a very small subset of the original ZINC15 dataset, provided as a sample dataset to briefly introduce the model training functionality of the BioNeMo Framework. This subset will be saved in /workspace/bionemo/examples/molecule/molmim/data by executing the following command.\n",
    "\n",
    "For this test run, the folder contains /train, /val, and /test subfolders, each containing molecular structures in SMILES format as CSV files. Check how many files have been created in these directories and adjust the TRAIN_FILE_RANGE, VAL_FILE_RANGE, and TEST_FILE_RANGE parameters in the example command below accordingly. The current command setup is configured to handle one file in each of the train, val, and test directories, containing 299069, 2, and 1486 samples respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8dc575-1cfe-426d-adaa-37b869863476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /workspace/bionemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0f8ee-60c3-4466-bc8c-3793a54bee32",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python examples/molecule/molmim/pretrain.py\\\n",
    " --config-path conf\\\n",
    " --config-name molmim_70m_24_3\\\n",
    " ++do_training=False\\\n",
    " ++trainer.devices=1 \\\n",
    " ++trainer.num_nodes=1 \\\n",
    " ++model.data.dataset_path=/workspace/bionemo/examples/molecule/molmim/data \\\n",
    " ++model.data.links_file=/workspace/bionemo/examples/molecule/megamolbart/dataset/ZINC-downloader-sample.txt \\\n",
    " ++exp_manager.create_wandb_logger=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a40bb-c39e-4884-aa2a-79a90c8ae944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import wandb\n",
    "with wandb.init(name=\"data_upload\") as run:\n",
    "    artifact = wandb.Artifact(\n",
    "        name=\"small_ZINC\",\n",
    "        type=\"dataset\",\n",
    "        description=\"subset of ZINC\",\n",
    "        metadata={\"path\":\"/workspace/bionemo/examples/molecule/molmim/data\"},\n",
    "    )\n",
    "    artifact.add_dir(\"/workspace/bionemo/examples/molecule/molmim/data\")\n",
    "    run.log_artifact(artifact)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1846e-7a33-4cc8-9a54-5e53ba1f1ba5",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37cb21-3b11-4c50-bf75-53c2f7b31eb1",
   "metadata": {},
   "source": [
    "For this test run, we will use the pre-configured parameters provided in the pretrain_small_canonicalized_logv.yaml configuration file located in the /workspace/bionemo/examples/molecule/molmim/conf folder. This configuration was used to train the MolMIM-70M-24.3 checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8d24e-e044-433a-8dfd-da782e1d4980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /workspace/bionemo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a2aaa-27ec-418b-9727-862a33348854",
   "metadata": {},
   "source": [
    "Please set the TRAIN_FILE_RANGE, TEST_FILE_RANGE, and VAL_FILE_RANGE according to the size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53884acd-f6b8-4887-9d93-56c91ca76b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TRAIN_FILE_RANGE=\"x_OP_000..175_CL_\"\n",
    "#TEST_FILE_RANGE=\"x_OP_000..004_CL_\"\n",
    "#VAL_FILE_RANGE=\"x_OP_000..175_CL_\"\n",
    "\n",
    "TRAIN_FILE_RANGE=\"x000\"\n",
    "TEST_FILE_RANGE=\"x000\"\n",
    "VAL_FILE_RANGE=\"x000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a529756-d097-420e-aeb6-75cb517a1804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HYDRA_FULL_ERROR\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b9c64-f3b9-4cfe-aedc-9586f5daa00f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python examples/molecule/molmim/pretrain.py\\\n",
    " --config-path conf\\\n",
    " --config-name molmim_70m_24_3\\\n",
    " ++trainer.devices=1 \\\n",
    " ++trainer.num_nodes=1 \\\n",
    " ++trainer.max_steps=1000 \\\n",
    " ++trainer.accumulate_grad_batches=1 \\\n",
    " ++trainer.val_check_interval=5 \\\n",
    " ++trainer.limit_val_batches=1.0 \\\n",
    " ++trainer.precision=32 \\\n",
    " ++model.micro_batch_size=128 \\\n",
    " ++model.global_batch_size=128 \\\n",
    " ++model.dwnstr_task_validation.enabled=False \\\n",
    " ++model.data.dataset_path=examples/molecule/molmim/data \\\n",
    " ++model.data.dataset.train=$TRAIN_FILE_RANGE \\\n",
    " ++model.data.dataset.val=$VAL_FILE_RANGE \\\n",
    " ++model.data.dataset.test=$TEST_FILE_RANGE \\\n",
    " ++model.data.index_mapping_dir=/results/data_index/ \\\n",
    " ++model.seq_length=128 \\\n",
    " ++exp_manager.exp_dir=/results/logs/ \\\n",
    " ++exp_manager.create_wandb_logger=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d982b08-4569-4fa2-927a-129966ef9d57",
   "metadata": {},
   "source": [
    "#  Property-guided molecular optimization using MolMIM with CMA-ES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33551259-5e74-4fa4-8d8e-052bb11990cc",
   "metadata": {},
   "source": [
    "This session demonstrates how to load a MolMIM checkpoint from the BioNeMo Framework, optimize several molecules of interest using a custom user-defined scoring function, and select novel related molecules expected to improve performance as measured by the scoring function using CMA-ES to traverse the latent space of the MolMIM model. To sample these molecules, the following steps must be completed:\n",
    "\n",
    "1. Load the desired MolMIM checkpoint.\n",
    "\n",
    "2. Encode the starting molecule into the latent space of MolMIM.\n",
    "\n",
    "3. Execute CMA-ES, repeating the following:\n",
    "* Decode the latent representations into SMILES strings.\n",
    "* Apply the user-defined scoring function to these SMILES strings, generating pairs of SMILES/scores.\n",
    "* Request a new set of latent space representations from the CMA-ES algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add7c5f6-e43c-4bfa-95a8-c3aa69ecd5cd",
   "metadata": {},
   "source": [
    "Next, we will download the pretrained model. To download the model, you need to install ngc and set up ngc config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1edf9-d437-4572-b3ab-f6117ae1224f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"WANDB_ENTITY\"]=\"wandb-healthcare\"\n",
    "os.environ[\"WANDB_PROJECT\"]=\"BioNeMo_Molecure_optimization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2131397-298c-4949-9eef-aa0ba97bfeb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install optuna statsmodels -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119634af-3177-4631-82e6-3e48dc4c0186",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -q -O /tmp/ngccli_linux.zip --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.38.0/files/ngccli_linux.zip && unzip -o /tmp/ngccli_linux.zip -d /tmp && chmod u+x /tmp/ngc-cli/ngc && rm /tmp/ngccli_linux.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67851ebf-79fe-4b96-a24f-d9be76d9c5e7",
   "metadata": {},
   "source": [
    "Next, to download a pretrained model, you will need to install NGC (NVIDIA GPU Cloud) and configure your NGC settings. Here’s how you can proceed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7d63b-649c-4d00-ba01-be0e494bcb13",
   "metadata": {
    "tags": []
   },
   "source": [
    "/tmp/ngc-cli/ngc config set\n",
    "\n",
    "/tmp/ngc-cli/ngc config set\n",
    "\n",
    "To complete the configuration of your NGC CLI, follow these steps, inputting the requested details:\n",
    "\n",
    "`API Key`: Enter your API key from the NVIDIA GPU Cloud (NGC). This key is critical for authentication and accessing the services.\n",
    "\n",
    "`CLI Output Format`: You can choose the desired output format for your CLI responses. If unsure, the default format is usually fine, so just press \"Enter\".\n",
    "\n",
    "`Organization (Org)`: Choose an organization other than 'no-org'. If you are part of an NVIDIA-approved organization, input its name; otherwise, consult NGC documentation or your NGC account settings for possible values.\n",
    "\n",
    "`Team`: If your NGC usage involves a specific team setup, enter the team name. If not, just press \"Enter\" to skip this step.\n",
    "\n",
    "`ACE`: This is typically for advanced configuration settings related to application, compute, and environment. Press \"Enter\" to accept default settings unless specific modifications are required.\n",
    "\n",
    "After configuring NGC, you can download the model using the command below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a9f2a-286b-497c-80a9-067783873943",
   "metadata": {
    "tags": []
   },
   "source": [
    "最後に、下記のコマンドを入力すれば、モデルをダウンロードできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e23e3a-3681-4b33-8a06-570cf6f54fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /workspace/bionemo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3e809-f04d-477d-9c28-9348bb55f670",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python download_models.py --download_dir /workspace/bionemo/models molmim_70m_24_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa10a66-bd4a-40bc-8875-caae41de836a",
   "metadata": {},
   "source": [
    "## Load the checkpoint into the molmim inference wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6716e-f862-41b1-a823-d4ee55024314",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bionemo.utils.hydra import load_model_config\n",
    "import os\n",
    "from bionemo.model.molecule.molmim.infer import MolMIMInference\n",
    "bionemo_home=f\"/workspace/bionemo\"\n",
    "os.environ['BIONEMO_HOME'] = bionemo_home\n",
    "checkpoint_path = f\"{bionemo_home}/models/molecule/molmim/molmim_70m_24_3.nemo\"\n",
    "cfg = load_model_config(config_name=\"molmim_infer.yaml\", config_path=f\"{bionemo_home}/examples/tests/conf/\") # reasonable starting config for molmim inference\n",
    "# This is the field of the config that we need to set to our desired checkpoint path.\n",
    "cfg.model.downstream_task.restore_from_path = checkpoint_path\n",
    "model = MolMIMInference(cfg, interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f08d939-b9fe-43a3-ab4b-b4035508b9e8",
   "metadata": {},
   "source": [
    "## Setting Up User-Defined Molecular Scoring Functions\n",
    "In this section, users can incorporate their own scoring functions that they want to optimize. In this example, we optimize a combination of Tanimoto similarity and Quantitative Estimate of Drug-likeness (QED) with the input molecule. This follows the example from the first MolMIM paper:\n",
    "\n",
    "<h3><center>score=min (QED/0.9, 1) + min (Tanimoto/0.4, 1)</center></h3>\n",
    "In this case, the model is allowed to optimize up to a maximum of QED 0.9 and Tanimoto similarity 0.4. Once these maximums are achieved, no further optimization is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49488d3f-147a-4639-8548-9421abcf0881",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from guided_molecule_gen.oracles import qed, tanimoto_similarity\n",
    "\n",
    "def score_mixing_function(qeds, similarities):\n",
    "    # We want to maximize QED and tanimoto similarity up to 0.9 and 0.4, respectively.\n",
    "    return np.clip(qeds / 0.9, a_min=0.0, a_max=1.0) + np.clip(similarities / 0.4, a_min=0.0, a_max=1.0)\n",
    "\n",
    "def try_canon(smiles:str) -> Optional[str]:\n",
    "    try:\n",
    "        return Chem.MolToSmiles(Chem.MolFromSmiles(smiles), canonical=True)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def canonicalize(smiles: List[str]) -> List[str]:\n",
    "    return [try_canon(s) for s in smiles]\n",
    "\n",
    "\n",
    "def scoring_function(smiles: List[str], reference:str, **kwargs) -> np.ndarray:\n",
    "    \"\"\"Takes a list of SMILES strings and returns an array of scores.\n",
    "\n",
    "    Args:\n",
    "        smiles (List[str]): Smiles strings to generate a score for (one each)\n",
    "        reference (str): Reference molecule (SMILES string) is also used for this scoring function.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of scores, one for each input SMILES string.\n",
    "    \"\"\"\n",
    "    #csmiles = canonicalize(smiles)\n",
    "    scores: np.ndarray = score_mixing_function(qed(smiles), tanimoto_similarity(smiles, reference))\n",
    "    return -1 * scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc390e2-0cdc-46cf-a689-f7359284b58b",
   "metadata": {},
   "source": [
    "## Definition of Starting Molecules\n",
    "In this section, we define the starting molecules for the optimization process. As examples, we will use imatinib, erlotinib, and gefitinib. Ensure that the SMILES strings representing these molecules are canonicalized using RDKit. Since MolMIM is trained on a corpus of SMILES strings canonicalized with RDKit, both the input and output should also be canonicalized with RDKit to achieve the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324d7bd-b0f5-4f8a-9792-185eb80c5418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.QED import qed as rdkit_qed\n",
    "\n",
    "# SMILES strings and compound names\n",
    "compound_names = [\"Imatinib\", \"Erlotinib\", \"Gifitinib\"]\n",
    "starting_smiles = [\n",
    "    \"CC1=C(C=C(C=C1)NC(=O)C2=CC=C(C=C2)CN3CCN(CC3)C)NC4=NC=CC(=N4)C5=CN=CC=C5\", # Imatinib\n",
    "    \"COCCOC1=C(C=C2C(=C1)C(=NC=N2)NC3=CC=CC(=C3)C#C)OCCOC\", # Erlotinib\n",
    "    \"C1COCCN1CCCOc2c(OC)cc3ncnc(c3c2)Nc4cc(Cl)c(F)cc4\", # Gifitinib\n",
    "]\n",
    "\n",
    "# Generate RDKit molecules from SMILES\n",
    "molecules = [Chem.MolFromSmiles(smile) for smile in starting_smiles]\n",
    "\n",
    "# Calculate QED scores\n",
    "starting_qed = [rdkit_qed(mol) for mol in molecules]\n",
    "\n",
    "# Generate canonical SMILES\n",
    "canonicalized_smiles = [Chem.MolToSmiles(mol, canonical=True) for mol in molecules]\n",
    "\n",
    "# Initialize a W&B run\n",
    "with wandb.init(name=\"simple-EDA\") as run:\n",
    "\n",
    "    # Create a W&B Table\n",
    "    table = wandb.Table(columns=[\"Compound Name\", \"SMILES\", \"Canonical SMILES\", \"Structure\"])\n",
    "\n",
    "    # Add data to the table\n",
    "    for name, smiles, canonical, mol in zip(compound_names, starting_smiles, canonicalized_smiles, molecules):\n",
    "        wandb_molecule = wandb.Molecule.from_rdkit(mol)\n",
    "        table.add_data(name, smiles, canonical, wandb_molecule)\n",
    "\n",
    "    # Log the table to W&B\n",
    "    run.log({\"Chemical Structures\": table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe62c1-9d00-410b-bed3-af3424559f27",
   "metadata": {},
   "source": [
    "## Configuring the Optimizer and Wrapping the Inference API for CMA-ES\n",
    "The CMA-ES library expects the input/output of the inference model to be in a specific format. Therefore, we provide a wrapper for this, and below we demonstrate how to set up the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aeb45f-6bd9-431a-b6c1-6cb83a3524b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bionemo.model.core.controlled_generation import ControlledGenerationPerceiverEncoderInferenceWrapper\n",
    "\n",
    "controlled_gen_kwargs = {\n",
    "    \"sampling_method\": \"beam-search\",\n",
    "    \"sampling_kwarg_overrides\": {\"beam_size\": 3, \"keep_only_best_tokens\": True, \"return_scores\": False},\n",
    "}\n",
    "\n",
    "model_wrapped = ControlledGenerationPerceiverEncoderInferenceWrapper(\n",
    "    model, enforce_perceiver=True, hidden_steps=1, **controlled_gen_kwargs\n",
    ")  # just flatten the position for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da0023-3bd6-40f1-baff-f1729047a832",
   "metadata": {},
   "source": [
    "## CMA-ES tuning\n",
    "Different models require different optimal settings for CMA-ES. Here, we perform a grid search over possible values of sigma and then carry out further optimization steps with the best settings. To optimize this sigma hyperparameter, we use the Optuna library. This process is called Hyperparameter Optimization (HPO).\n",
    "Let's look at the HPO process with Optuna and the optimal sigma values found using wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010497b9-57fa-475e-8eeb-990561a32089",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from guided_molecule_gen.optimizer import MoleculeGenerationOptimizer\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def objective(trial, n_steps:int=10):\n",
    "    sigma = trial.suggest_float('sigma', 0, 2)\n",
    "    optimizer = MoleculeGenerationOptimizer(\n",
    "        model_wrapped,\n",
    "        scoring_function,\n",
    "        canonicalized_smiles,\n",
    "        popsize=10,  # larger values will be slower but more thorough\n",
    "        optimizer_args={\"sigma\": sigma},\n",
    "    )\n",
    "\n",
    "    optimizer.optimize(n_steps)\n",
    "    final_smiles = optimizer.generated_smis\n",
    "    final_score = np.mean([np.min(scoring_function(smis_population, reference_smis)) for smis_population,reference_smis in zip(final_smiles, canonicalized_smiles)])\n",
    "    wandb.log({\"score\": final_score, \"sigma\": sigma})\n",
    "    return final_score\n",
    "\n",
    "with wandb.init(name=f\"Basic_Optuna_{datetime.now().strftime('%Y%m%d_%H%M%S')}\") as run:\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    # After the study, log the best parameters and the DataFrame\n",
    "    best_params = study.best_params\n",
    "    wandb.log({\"best_params\": best_params})\n",
    "\n",
    "    # Get a DataFrame of all trials and save it as a W&B Table\n",
    "    df = study.trials_dataframe()\n",
    "    wandb_table = wandb.Table(dataframe=df)\n",
    "    wandb.log({\"optuna_history_table\": wandb_table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07400851-d470-4877-8eda-2bf805a457d0",
   "metadata": {},
   "source": [
    "上記の値はHPOプロセスで得られた最適値ですが、有効な値の範囲を考慮し、よりロバストであろう最小値を選択します。HPOプロセスは確率的なため、高性能な値と低性能な値が近接して存在することがあります。オプティマイザが一般的に良好に機能するシグマ値の適切な範囲を特定したいと考えています。滑らかにした最適な選択と、最も良い名目上の選択をwandb上で比較しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327ed8c-65e8-49c4-809d-2461bd227e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from guided_molecule_gen.optimizer import MoleculeGenerationOptimizer\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def lowess_with_confidence_bounds(x, y, eval_x, N=200, conf_interval=0.95, lowess_kw=None):\n",
    "    \"\"\"\n",
    "    Perform Lowess regression and determine a confidence interval by bootstrap resampling.\n",
    "    \"\"\"\n",
    "    # Lowess smoothing\n",
    "    smoothed = sm.nonparametric.lowess(exog=x, endog=y, xvals=eval_x, **lowess_kw)\n",
    "\n",
    "    # Bootstrap resampling for confidence intervals\n",
    "    smoothed_values = np.empty((N, len(eval_x)))\n",
    "    for i in range(N):\n",
    "        sample = np.random.choice(len(x), len(x), replace=True)\n",
    "        sampled_x = x[sample]\n",
    "        sampled_y = y[sample]\n",
    "        smoothed_values[i, :] = sm.nonparametric.lowess(exog=sampled_x, endog=sampled_y, xvals=eval_x, **lowess_kw)\n",
    "        \n",
    "\n",
    "    # Confidence intervals\n",
    "    sorted_values = np.sort(smoothed_values, axis=0)\n",
    "    bound = int(N * (1 - conf_interval) / 2)\n",
    "    bottom = sorted_values[bound - 1]\n",
    "    top = sorted_values[-bound]\n",
    "\n",
    "    return smoothed, bottom, top\n",
    "\n",
    "\n",
    "# Initialize a W&B run\n",
    "with wandb.init(name=f\"HPO_visualization_{datetime.now().strftime('%Y%m%d_%H%M%S')}\") as run:\n",
    "    # Generate data, fit and plot\n",
    "    completed_trials = [trial for trial in study.trials if trial.state == optuna.trial.TrialState.COMPLETE]\n",
    "    trials_data = [{\"sigma\": trial.params[\"sigma\"], \"loss\": trial.value, \"trial_id\": tid} for tid,trial in enumerate(completed_trials)]\n",
    "    data = pd.DataFrame(trials_data)\n",
    "    data = pd.DataFrame(trials_data)\n",
    "    eval_x = np.linspace(0, 2, 200)\n",
    "    smoothed, bottom, top = lowess_with_confidence_bounds(data.sigma, data.loss, eval_x, lowess_kw={\"frac\": 0.33})\n",
    "\n",
    "    # Create plot\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(data[\"sigma\"], data[\"loss\"], label=\"Observed Points\")\n",
    "    ax.plot(eval_x, smoothed, 'k', label=\"LOWESS Smoothed\")\n",
    "    ax.fill_between(eval_x, bottom, top, color='blue', alpha=0.5, label=\"95% Confidence Interval\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Loss vs Sigma with LOWESS Fit\")\n",
    "    \n",
    "    # Log the plot to W&B\n",
    "    run.log({\"LOWESS Plot\": wandb.Image(fig)})\n",
    "\n",
    "    # Additional data to log\n",
    "    smoothed_best_sigma = eval_x[np.argmin(smoothed)]  # Use the smoothed minimum\n",
    "    run.log({\"best_params\": study.best_params, \"smoothed_best_sigma\": smoothed_best_sigma})\n",
    "    smooth_best = {\"sigma\": smoothed_best_sigma}\n",
    "    print(\"smooth_best:\", smooth_best, \"simple_best_param:\",study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b75b92-bca1-4c1f-9484-cce2ef63f22b",
   "metadata": {},
   "source": [
    "## CMA-ES Optimization\n",
    "### Conducting a Larger-Scale CMA-ES Optimization with the Discovered Parameters\n",
    "Since the sigma values found through HPO have proven effective, we increase the size of the molecular population and the number of steps to finally perform a larger-scale optimization.\n",
    "\n",
    "### Exploring the Results\n",
    "To assess the performance of the optimization, we can quantify the number of invalid samples produced. \"Invalid\" refers to SMILES strings that do not represent chemically viable molecules.\n",
    "After the run, we will create graphs showing how the components of the target (QED and Tanimoto similarity) changed in each iteration. According to the definition of the target, values of Tanimoto similarity above 0.4 are considered optimal, so noise around this value is expected. Similarly, for QED, values above 0.9 are considered optimal, so if there are molecules exceeding this threshold, noise around these values is also expected.\n",
    "Let's check the results in WandB.\n",
    "\n",
    "### How Good Was the Optimization Performance?\n",
    "To evaluate the performance of the optimization, we can quantify the number of invalid samples produced. \"Invalid\" refers to SMILES strings that do not represent chemically viable molecules.\n",
    "\n",
    "-> Check num_of_bad_samples in wandb\n",
    "\n",
    "Ultimately, we can quantify the degree of QED improvement relative to baseline values and the percentage of optimized molecules that maintained the desired Tanimoto similarity threshold of above 0.4.\n",
    "\n",
    "-> Check mean_qed_improvement and tanimoto_above_04 in wandb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21eccc-198e-4e53-977b-df0ec5eb66ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from guided_molecule_gen.optimizer import MoleculeGenerationOptimizer\n",
    "from tqdm import trange\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize a W&B run\n",
    "with wandb.init(name=f\"CMS_EA_Optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}\") as run:\n",
    "    # Assuming model_wrapped and scoring_function are defined elsewhere\n",
    "    optimizer = MoleculeGenerationOptimizer(\n",
    "        model_wrapped,\n",
    "        scoring_function,\n",
    "        canonicalized_smiles,\n",
    "        popsize=50,  # larger values will be slower but more thorough\n",
    "        optimizer_args=smooth_best,  # Vals from HPO\n",
    "    )\n",
    "    \n",
    "    columns = [\"iteration\", \"idx\",\"molecure\", \"smiles\", \"structure\", \"qud_score\", \"tanimoto_score\"]\n",
    "    optimization_results = wandb.Table(columns=columns)\n",
    "\n",
    "    # Starting state for idx 0\n",
    "    qed_scores = [qed(canonicalized_smiles)]\n",
    "    tanimoto_scores = [[tanimoto_similarity([canonicalized_smiles[idx]], canonicalized_smiles[idx])[0] for idx in range(len(canonicalized_smiles))]]\n",
    "    best_molecules = [canonicalized_smiles]\n",
    "    fraction_bad_samples = [[0] * len(canonicalized_smiles)]\n",
    "\n",
    "    for i in trange(30):\n",
    "        optimizer.step()\n",
    "        final_smiles = optimizer.generated_smis\n",
    "        # Population of molecules is returned, but we only want the best one.\n",
    "        _qed_scores = []\n",
    "        _tanimoto_scores = []\n",
    "        _best_molecules = []\n",
    "        _fraction_bad = []\n",
    "        ca_id = 0\n",
    "        for smis_population, reference_smis in zip(final_smiles, canonicalized_smiles):\n",
    "            idx = np.argmin(scoring_function(smis_population, reference_smis))\n",
    "            _fraction_bad.append(np.mean(qed(smis_population) == 0))\n",
    "            _best_molecules.append(smis_population[idx])\n",
    "            _qed_scores.append(qed([smis_population[idx]])[0])\n",
    "            _tanimoto_scores.append(tanimoto_similarity([smis_population[idx]], reference_smis)[0])\n",
    "            \n",
    "            \n",
    "            mol = Chem.MolFromSmiles(smis_population[idx])\n",
    "            wandb_molecule = wandb.Molecule.from_rdkit(mol)\n",
    "            \n",
    "            optimization_results.add_data(i, idx,[\"imatinib\", \"erlotinib\", \"gifitinib\"][ca_id], smis_population[idx], wandb_molecule, qed([smis_population[idx]])[0], tanimoto_similarity([smis_population[idx]], reference_smis)[0])\n",
    "            ca_id=+1\n",
    "\n",
    "        qed_scores.append(_qed_scores)\n",
    "        tanimoto_scores.append(_tanimoto_scores)\n",
    "        best_molecules.append(_best_molecules)\n",
    "        fraction_bad_samples.append(_fraction_bad)\n",
    "\n",
    "    run.log({\"optimization_results\":optimization_results})\n",
    "\n",
    "    # Plotting results\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, molecule in enumerate([\"imatinib\", \"erlotinib\", \"gifitinib\"]):\n",
    "        line, = plt.plot(np.arange(len(qed_scores)), [q[i] for q in qed_scores], label=f\"{molecule} QED\")\n",
    "        color = line.get_color()\n",
    "        plt.plot(np.arange(len(tanimoto_scores)), [t[i] for t in tanimoto_scores], label=f\"{molecule} Tanimoto\", linestyle=\"--\", color=color)\n",
    "    plt.axhline(y=0.9, color='r', linestyle='-', label=\"QED target\")\n",
    "    plt.axhline(y=0.4, color='r', linestyle='--', label=\"Tanimoto target\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"QED or Tanimoto similarity\")\n",
    "    plt.title(\"Targets over time for MolMIM model\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Log the plot to W&B\n",
    "    run.log({\"LOWESS Plot\": wandb.Image(fig)})\n",
    "\n",
    "    # Additional calculations and logs\n",
    "    qed_improvements = []\n",
    "    tanimoto_above_04 = []\n",
    "    for i in range(len(starting_qed)):\n",
    "        tanimoto_above_04.append(tanimoto_scores[-1][i] >= 0.4)\n",
    "        qed_improvements.append(qed_scores[-1][i] - starting_qed[i])\n",
    "    \n",
    "    metrics = {\n",
    "        \"num_of_bad_samples\": np.mean(fraction_bad_samples),\n",
    "        \"mean_qed_improvement\": np.mean(qed_improvements),\n",
    "        \"tanimoto_above_04\": np.mean(tanimoto_above_04),\n",
    "    }\n",
    "    \n",
    "    run.log(metrics)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"num_of_bad_samples:\", np.mean(fraction_bad_samples),\"mean_qed_improvement:\", metrics[\"mean_qed_improvement\"], \"tanimoto_above_04:\", metrics[\"tanimoto_above_04\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34751fe-8d70-4044-a4e8-ee0b81d0a501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
